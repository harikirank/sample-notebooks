{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9b47b80",
   "metadata": {},
   "source": [
    "# Logistic Regression by Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d005ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relavent packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c1612030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup or get the data\n",
    "#x should be 2D. reshape() will convert 1D to 2D array\n",
    "#-1: as many rows possible. 1: one column \n",
    "x = np.arange(159).reshape(-1,1)\n",
    "y = np.array([0,0,0,0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,\n",
    "             0,0,0,0,1,1,1,1,1,1, 0,0,0,0,1,1,1,1,1,1,\n",
    "             0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,\n",
    "              0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,\n",
    "              0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,\n",
    "              1,1,0,1,0,0,0,1,1,1,1,0,1,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "be56717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model and train it1,\n",
    "#liblinear: Library for large linear classification\n",
    "#default C=1\n",
    "model = LogisticRegression(solver='lbfgs', random_state=0).fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cee90c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model by fitting it with data to find coefficients\n",
    "#b0, b1, b2, etc. of a polynomial cost function\n",
    "#model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "242b74e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show all the labels in the logistic regression\n",
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "20e37516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24262261])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b0 is the intercept\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "df84627e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.002275]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b1, b2, etc. coefecients \n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "559b5425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ece66a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43964015, 0.56035985],\n",
       "       [0.43907977, 0.56092023],\n",
       "       [0.43851954, 0.56148046],\n",
       "       [0.43795947, 0.56204053],\n",
       "       [0.43739956, 0.56260044],\n",
       "       [0.4368398 , 0.5631602 ],\n",
       "       [0.43628021, 0.56371979],\n",
       "       [0.43572078, 0.56427922],\n",
       "       [0.43516151, 0.56483849],\n",
       "       [0.43460241, 0.56539759],\n",
       "       [0.43404347, 0.56595653],\n",
       "       [0.4334847 , 0.5665153 ],\n",
       "       [0.4329261 , 0.5670739 ],\n",
       "       [0.43236768, 0.56763232],\n",
       "       [0.43180942, 0.56819058],\n",
       "       [0.43125133, 0.56874867],\n",
       "       [0.43069343, 0.56930657],\n",
       "       [0.43013569, 0.56986431],\n",
       "       [0.42957814, 0.57042186],\n",
       "       [0.42902076, 0.57097924],\n",
       "       [0.42846356, 0.57153644],\n",
       "       [0.42790654, 0.57209346],\n",
       "       [0.42734971, 0.57265029],\n",
       "       [0.42679306, 0.57320694],\n",
       "       [0.4262366 , 0.5737634 ],\n",
       "       [0.42568032, 0.57431968],\n",
       "       [0.42512423, 0.57487577],\n",
       "       [0.42456833, 0.57543167],\n",
       "       [0.42401262, 0.57598738],\n",
       "       [0.42345711, 0.57654289],\n",
       "       [0.42290178, 0.57709822],\n",
       "       [0.42234665, 0.57765335],\n",
       "       [0.42179172, 0.57820828],\n",
       "       [0.42123699, 0.57876301],\n",
       "       [0.42068245, 0.57931755],\n",
       "       [0.42012811, 0.57987189],\n",
       "       [0.41957398, 0.58042602],\n",
       "       [0.41902005, 0.58097995],\n",
       "       [0.41846632, 0.58153368],\n",
       "       [0.4179128 , 0.5820872 ],\n",
       "       [0.41735948, 0.58264052],\n",
       "       [0.41680637, 0.58319363],\n",
       "       [0.41625347, 0.58374653],\n",
       "       [0.41570078, 0.58429922],\n",
       "       [0.41514831, 0.58485169],\n",
       "       [0.41459605, 0.58540395],\n",
       "       [0.414044  , 0.585956  ],\n",
       "       [0.41349216, 0.58650784],\n",
       "       [0.41294055, 0.58705945],\n",
       "       [0.41238915, 0.58761085],\n",
       "       [0.41183798, 0.58816202],\n",
       "       [0.41128702, 0.58871298],\n",
       "       [0.41073629, 0.58926371],\n",
       "       [0.41018578, 0.58981422],\n",
       "       [0.40963549, 0.59036451],\n",
       "       [0.40908543, 0.59091457],\n",
       "       [0.4085356 , 0.5914644 ],\n",
       "       [0.407986  , 0.592014  ],\n",
       "       [0.40743663, 0.59256337],\n",
       "       [0.40688748, 0.59311252],\n",
       "       [0.40633858, 0.59366142],\n",
       "       [0.4057899 , 0.5942101 ],\n",
       "       [0.40524146, 0.59475854],\n",
       "       [0.40469326, 0.59530674],\n",
       "       [0.40414529, 0.59585471],\n",
       "       [0.40359757, 0.59640243],\n",
       "       [0.40305008, 0.59694992],\n",
       "       [0.40250283, 0.59749717],\n",
       "       [0.40195583, 0.59804417],\n",
       "       [0.40140907, 0.59859093],\n",
       "       [0.40086256, 0.59913744],\n",
       "       [0.40031629, 0.59968371],\n",
       "       [0.39977028, 0.60022972],\n",
       "       [0.39922451, 0.60077549],\n",
       "       [0.39867899, 0.60132101],\n",
       "       [0.39813372, 0.60186628],\n",
       "       [0.3975887 , 0.6024113 ],\n",
       "       [0.39704394, 0.60295606],\n",
       "       [0.39649943, 0.60350057],\n",
       "       [0.39595518, 0.60404482],\n",
       "       [0.39541119, 0.60458881],\n",
       "       [0.39486746, 0.60513254],\n",
       "       [0.39432398, 0.60567602],\n",
       "       [0.39378077, 0.60621923],\n",
       "       [0.39323782, 0.60676218],\n",
       "       [0.39269513, 0.60730487],\n",
       "       [0.39215271, 0.60784729],\n",
       "       [0.39161056, 0.60838944],\n",
       "       [0.39106867, 0.60893133],\n",
       "       [0.39052705, 0.60947295],\n",
       "       [0.3899857 , 0.6100143 ],\n",
       "       [0.38944462, 0.61055538],\n",
       "       [0.38890381, 0.61109619],\n",
       "       [0.38836328, 0.61163672],\n",
       "       [0.38782302, 0.61217698],\n",
       "       [0.38728304, 0.61271696],\n",
       "       [0.38674333, 0.61325667],\n",
       "       [0.3862039 , 0.6137961 ],\n",
       "       [0.38566475, 0.61433525],\n",
       "       [0.38512589, 0.61487411],\n",
       "       [0.3845873 , 0.6154127 ],\n",
       "       [0.38404899, 0.61595101],\n",
       "       [0.38351097, 0.61648903],\n",
       "       [0.38297324, 0.61702676],\n",
       "       [0.38243579, 0.61756421],\n",
       "       [0.38189863, 0.61810137],\n",
       "       [0.38136175, 0.61863825],\n",
       "       [0.38082517, 0.61917483],\n",
       "       [0.38028888, 0.61971112],\n",
       "       [0.37975288, 0.62024712],\n",
       "       [0.37921717, 0.62078283],\n",
       "       [0.37868176, 0.62131824],\n",
       "       [0.37814664, 0.62185336],\n",
       "       [0.37761182, 0.62238818],\n",
       "       [0.37707729, 0.62292271],\n",
       "       [0.37654307, 0.62345693],\n",
       "       [0.37600915, 0.62399085],\n",
       "       [0.37547552, 0.62452448],\n",
       "       [0.3749422 , 0.6250578 ],\n",
       "       [0.37440918, 0.62559082],\n",
       "       [0.37387647, 0.62612353],\n",
       "       [0.37334406, 0.62665594],\n",
       "       [0.37281196, 0.62718804],\n",
       "       [0.37228017, 0.62771983],\n",
       "       [0.37174868, 0.62825132],\n",
       "       [0.37121751, 0.62878249],\n",
       "       [0.37068665, 0.62931335],\n",
       "       [0.3701561 , 0.6298439 ],\n",
       "       [0.36962586, 0.63037414],\n",
       "       [0.36909594, 0.63090406],\n",
       "       [0.36856633, 0.63143367],\n",
       "       [0.36803704, 0.63196296],\n",
       "       [0.36750807, 0.63249193],\n",
       "       [0.36697941, 0.63302059],\n",
       "       [0.36645108, 0.63354892],\n",
       "       [0.36592307, 0.63407693],\n",
       "       [0.36539537, 0.63460463],\n",
       "       [0.36486801, 0.63513199],\n",
       "       [0.36434096, 0.63565904],\n",
       "       [0.36381424, 0.63618576],\n",
       "       [0.36328785, 0.63671215],\n",
       "       [0.36276179, 0.63723821],\n",
       "       [0.36223605, 0.63776395],\n",
       "       [0.36171064, 0.63828936],\n",
       "       [0.36118556, 0.63881444],\n",
       "       [0.36066082, 0.63933918],\n",
       "       [0.36013641, 0.63986359],\n",
       "       [0.35961233, 0.64038767],\n",
       "       [0.35908858, 0.64091142],\n",
       "       [0.35856517, 0.64143483],\n",
       "       [0.3580421 , 0.6419579 ],\n",
       "       [0.35751937, 0.64248063],\n",
       "       [0.35699697, 0.64300303],\n",
       "       [0.35647492, 0.64352508],\n",
       "       [0.3559532 , 0.6440468 ],\n",
       "       [0.35543183, 0.64456817],\n",
       "       [0.3549108 , 0.6450892 ],\n",
       "       [0.35439011, 0.64560989],\n",
       "       [0.35386977, 0.64613023]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the model. Returns matrix of probabilities\n",
    "#that predict output is either 0 or 1\n",
    "model.predict_proba(x)\n",
    "#in this matrix, each row is one observation\n",
    "#first column is the probability that output is 0\n",
    "#second column is the probability that output is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "deec751e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find actual predictions based on the probability matrix \n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "87ec644c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6037735849056604"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x,y)\n",
    "#provides the ratio of # of correct predictions to total # of \n",
    "#observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e3b74662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 63],\n",
       "       [ 0, 96]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e0dc61",
   "metadata": {},
   "source": [
    "# Let's improve the Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "da65a9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10.0, random_state=0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10.0, random_state=0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10.0, random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets setup regularization of training dataset. Smaller C means larger regularization \n",
    "#data playout but watch for overfitting. Higher C means, dont believe training data\n",
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5555dafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23972421])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now collect model parameters. intercept, coefficiant, etc.\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e9d3c8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00230258]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "860646f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44035432, 0.55964568],\n",
       "       [0.43978694, 0.56021306],\n",
       "       [0.43921972, 0.56078028],\n",
       "       [0.43865266, 0.56134734],\n",
       "       [0.43808576, 0.56191424],\n",
       "       [0.43751902, 0.56248098],\n",
       "       [0.43695245, 0.56304755],\n",
       "       [0.43638604, 0.56361396],\n",
       "       [0.43581979, 0.56418021],\n",
       "       [0.43525371, 0.56474629],\n",
       "       [0.4346878 , 0.5653122 ],\n",
       "       [0.43412207, 0.56587793],\n",
       "       [0.4335565 , 0.5664435 ],\n",
       "       [0.4329911 , 0.5670089 ],\n",
       "       [0.43242588, 0.56757412],\n",
       "       [0.43186084, 0.56813916],\n",
       "       [0.43129597, 0.56870403],\n",
       "       [0.43073129, 0.56926871],\n",
       "       [0.43016678, 0.56983322],\n",
       "       [0.42960245, 0.57039755],\n",
       "       [0.42903831, 0.57096169],\n",
       "       [0.42847435, 0.57152565],\n",
       "       [0.42791058, 0.57208942],\n",
       "       [0.42734699, 0.57265301],\n",
       "       [0.42678359, 0.57321641],\n",
       "       [0.42622039, 0.57377961],\n",
       "       [0.42565737, 0.57434263],\n",
       "       [0.42509455, 0.57490545],\n",
       "       [0.42453192, 0.57546808],\n",
       "       [0.42396948, 0.57603052],\n",
       "       [0.42340725, 0.57659275],\n",
       "       [0.42284521, 0.57715479],\n",
       "       [0.42228337, 0.57771663],\n",
       "       [0.42172173, 0.57827827],\n",
       "       [0.42116029, 0.57883971],\n",
       "       [0.42059906, 0.57940094],\n",
       "       [0.42003804, 0.57996196],\n",
       "       [0.41947722, 0.58052278],\n",
       "       [0.4189166 , 0.5810834 ],\n",
       "       [0.4183562 , 0.5816438 ],\n",
       "       [0.41779601, 0.58220399],\n",
       "       [0.41723603, 0.58276397],\n",
       "       [0.41667626, 0.58332374],\n",
       "       [0.41611671, 0.58388329],\n",
       "       [0.41555737, 0.58444263],\n",
       "       [0.41499825, 0.58500175],\n",
       "       [0.41443935, 0.58556065],\n",
       "       [0.41388067, 0.58611933],\n",
       "       [0.41332222, 0.58667778],\n",
       "       [0.41276398, 0.58723602],\n",
       "       [0.41220597, 0.58779403],\n",
       "       [0.41164819, 0.58835181],\n",
       "       [0.41109063, 0.58890937],\n",
       "       [0.4105333 , 0.5894667 ],\n",
       "       [0.4099762 , 0.5900238 ],\n",
       "       [0.40941933, 0.59058067],\n",
       "       [0.40886269, 0.59113731],\n",
       "       [0.40830629, 0.59169371],\n",
       "       [0.40775012, 0.59224988],\n",
       "       [0.40719418, 0.59280582],\n",
       "       [0.40663849, 0.59336151],\n",
       "       [0.40608303, 0.59391697],\n",
       "       [0.40552782, 0.59447218],\n",
       "       [0.40497284, 0.59502716],\n",
       "       [0.40441811, 0.59558189],\n",
       "       [0.40386362, 0.59613638],\n",
       "       [0.40330938, 0.59669062],\n",
       "       [0.40275538, 0.59724462],\n",
       "       [0.40220164, 0.59779836],\n",
       "       [0.40164814, 0.59835186],\n",
       "       [0.40109489, 0.59890511],\n",
       "       [0.40054189, 0.59945811],\n",
       "       [0.39998915, 0.60001085],\n",
       "       [0.39943666, 0.60056334],\n",
       "       [0.39888443, 0.60111557],\n",
       "       [0.39833246, 0.60166754],\n",
       "       [0.39778074, 0.60221926],\n",
       "       [0.39722928, 0.60277072],\n",
       "       [0.39667809, 0.60332191],\n",
       "       [0.39612715, 0.60387285],\n",
       "       [0.39557648, 0.60442352],\n",
       "       [0.39502608, 0.60497392],\n",
       "       [0.39447594, 0.60552406],\n",
       "       [0.39392607, 0.60607393],\n",
       "       [0.39337646, 0.60662354],\n",
       "       [0.39282713, 0.60717287],\n",
       "       [0.39227807, 0.60772193],\n",
       "       [0.39172928, 0.60827072],\n",
       "       [0.39118076, 0.60881924],\n",
       "       [0.39063252, 0.60936748],\n",
       "       [0.39008455, 0.60991545],\n",
       "       [0.38953686, 0.61046314],\n",
       "       [0.38898945, 0.61101055],\n",
       "       [0.38844232, 0.61155768],\n",
       "       [0.38789547, 0.61210453],\n",
       "       [0.3873489 , 0.6126511 ],\n",
       "       [0.38680262, 0.61319738],\n",
       "       [0.38625662, 0.61374338],\n",
       "       [0.38571091, 0.61428909],\n",
       "       [0.38516548, 0.61483452],\n",
       "       [0.38462034, 0.61537966],\n",
       "       [0.3840755 , 0.6159245 ],\n",
       "       [0.38353094, 0.61646906],\n",
       "       [0.38298667, 0.61701333],\n",
       "       [0.3824427 , 0.6175573 ],\n",
       "       [0.38189902, 0.61810098],\n",
       "       [0.38135564, 0.61864436],\n",
       "       [0.38081256, 0.61918744],\n",
       "       [0.38026977, 0.61973023],\n",
       "       [0.37972728, 0.62027272],\n",
       "       [0.37918509, 0.62081491],\n",
       "       [0.37864321, 0.62135679],\n",
       "       [0.37810162, 0.62189838],\n",
       "       [0.37756034, 0.62243966],\n",
       "       [0.37701937, 0.62298063],\n",
       "       [0.3764787 , 0.6235213 ],\n",
       "       [0.37593834, 0.62406166],\n",
       "       [0.37539829, 0.62460171],\n",
       "       [0.37485855, 0.62514145],\n",
       "       [0.37431912, 0.62568088],\n",
       "       [0.37378   , 0.62622   ],\n",
       "       [0.37324119, 0.62675881],\n",
       "       [0.3727027 , 0.6272973 ],\n",
       "       [0.37216452, 0.62783548],\n",
       "       [0.37162666, 0.62837334],\n",
       "       [0.37108912, 0.62891088],\n",
       "       [0.3705519 , 0.6294481 ],\n",
       "       [0.370015  , 0.629985  ],\n",
       "       [0.36947842, 0.63052158],\n",
       "       [0.36894216, 0.63105784],\n",
       "       [0.36840623, 0.63159377],\n",
       "       [0.36787062, 0.63212938],\n",
       "       [0.36733533, 0.63266467],\n",
       "       [0.36680037, 0.63319963],\n",
       "       [0.36626575, 0.63373425],\n",
       "       [0.36573145, 0.63426855],\n",
       "       [0.36519748, 0.63480252],\n",
       "       [0.36466384, 0.63533616],\n",
       "       [0.36413053, 0.63586947],\n",
       "       [0.36359756, 0.63640244],\n",
       "       [0.36306492, 0.63693508],\n",
       "       [0.36253262, 0.63746738],\n",
       "       [0.36200065, 0.63799935],\n",
       "       [0.36146903, 0.63853097],\n",
       "       [0.36093774, 0.63906226],\n",
       "       [0.36040679, 0.63959321],\n",
       "       [0.35987619, 0.64012381],\n",
       "       [0.35934592, 0.64065408],\n",
       "       [0.358816  , 0.641184  ],\n",
       "       [0.35828642, 0.64171358],\n",
       "       [0.35775719, 0.64224281],\n",
       "       [0.35722831, 0.64277169],\n",
       "       [0.35669977, 0.64330023],\n",
       "       [0.35617158, 0.64382842],\n",
       "       [0.35564374, 0.64435626],\n",
       "       [0.35511626, 0.64488374],\n",
       "       [0.35458912, 0.64541088],\n",
       "       [0.35406234, 0.64593766],\n",
       "       [0.35353591, 0.64646409]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3edf3348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "125e88db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6037735849056604"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f458201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 63],\n",
       "       [ 0, 96]], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "95f38bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4492753623188406\n"
     ]
    }
   ],
   "source": [
    "#AUC computation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=0)\n",
    "y_pred = model.predict_proba(X_test)[::,1]\n",
    "auc = roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "print (auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "19043433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc info for logistic regression [0.         0.11111111 0.11111111 0.22222222 0.22222222 0.33333333\n",
      " 0.33333333 0.66666667 0.66666667 0.77777778 0.77777778 0.88888889\n",
      " 0.88888889 1.         1.        ] [0.         0.         0.08695652 0.08695652 0.34782609 0.34782609\n",
      " 0.47826087 0.47826087 0.65217391 0.65217391 0.73913043 0.73913043\n",
      " 0.7826087  0.7826087  1.        ] [1.641184   0.641184   0.63799935 0.63373425 0.62081491 0.6126511\n",
      " 0.60717287 0.59447218 0.59113731 0.5900238  0.58444263 0.58220399\n",
      " 0.58052278 0.57827827 0.56361396]\n"
     ]
    }
   ],
   "source": [
    "#ROC computation\n",
    "from sklearn.metrics import roc_curve, roc_auc_score \n",
    "len(y_test)\n",
    "len(X_test)\n",
    "#the following will be run once for each algorithm\n",
    "fpr, tpr, threshold = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "print ('roc info for logistic regression', fpr, tpr, threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlreg",
   "language": "python",
   "name": "mlreg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
